{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "368686b4-f487-4dd4-aeff-37823976529d"
      },
      "source": [
        "# Evaluate Multi-Modal LLM using Google's Gemini model for image understanding and multi-modal RAG\n",
        "\n",
        "In the first example, run and evaluate a multimodal Gemini model with a multimodal evaluator.\n",
        "\n",
        "In the second example, learn how to run semantic evaluations on a multi-modal RAG, including the RAG triad.\n",
        "\n",
        "Note: `google-generativeai` is only available for certain countries and regions. Original example attribution: Llama-Index\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/models/gemini_multi_modal.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc691ca8",
        "outputId": "effa88c9-e035-4502-8e7c-550e5e292873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: trulens-eval==0.19.2 in /opt/homebrew/lib/python3.9/site-packages (0.19.2)\n",
            "Requirement already satisfied: llama-index in /opt/homebrew/lib/python3.9/site-packages (0.9.17)\n",
            "Requirement already satisfied: google-generativeai>=0.3.0 in /opt/homebrew/lib/python3.9/site-packages (0.3.1)\n",
            "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.9/site-packages (3.8.2)\n",
            "Requirement already satisfied: qdrant_client in /opt/homebrew/lib/python3.9/site-packages (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.26.2)\n",
            "Requirement already satisfied: frozendict>=2.3.8 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (2.3.10)\n",
            "Requirement already satisfied: munch>=3.0.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (4.0.0)\n",
            "Requirement already satisfied: dill>=0.3.7 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.3.7)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.0.0)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (2.5.2)\n",
            "Requirement already satisfied: merkle-json>=1.0.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.0.0)\n",
            "Requirement already satisfied: langchain>=0.0.335 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.0.351)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from trulens-eval==0.19.2) (4.9.0)\n",
            "Requirement already satisfied: millify>=0.1.1 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.1.1)\n",
            "Requirement already satisfied: humanize>=4.6.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (4.9.0)\n",
            "Requirement already satisfied: streamlit>=1.27.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.29.0)\n",
            "Requirement already satisfied: streamlit-aggrid>=0.3.4.post3 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.3.4.post3)\n",
            "Requirement already satisfied: streamlit-extras>=0.2.7 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.3.6)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.19 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (2.0.23)\n",
            "Requirement already satisfied: alembic>=1.11.2 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.13.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (4.12.2)\n",
            "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (1.2.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (2023.12.2)\n",
            "Requirement already satisfied: httpx in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (0.25.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (1.6.0)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.31.0 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (0.5.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (2.25.2)\n",
            "Requirement already satisfied: google-api-core in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (2.15.0)\n",
            "Requirement already satisfied: protobuf in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (4.25.1)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/homebrew/lib/python3.9/site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai>=0.3.0) (1.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /opt/homebrew/lib/python3.9/site-packages (from qdrant_client) (1.60.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /opt/homebrew/lib/python3.9/site-packages (from qdrant_client) (1.60.0)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /opt/homebrew/lib/python3.9/site-packages (from qdrant_client) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.14 in /opt/homebrew/lib/python3.9/site-packages (from qdrant_client) (1.26.18)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n",
            "Requirement already satisfied: Mako in /opt/homebrew/lib/python3.9/site-packages (from alembic>=1.11.2->trulens-eval==0.19.2) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /opt/homebrew/lib/python3.9/site-packages (from deprecated>=1.2.9.3->llama-index) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/homebrew/lib/python3.9/site-packages (from google-api-core->google-generativeai>=0.3.0) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from google-auth->google-generativeai>=0.3.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/lib/python3.9/site-packages (from google-auth->google-generativeai>=0.3.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/lib/python3.9/site-packages (from google-auth->google-generativeai>=0.3.0) (4.9)\n",
            "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.9/site-packages (from grpcio-tools>=1.41.0->qdrant_client) (60.10.0)\n",
            "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (4.2.0)\n",
            "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (1.0.2)\n",
            "Requirement already satisfied: idna in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (3.6)\n",
            "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /opt/homebrew/lib/python3.9/site-packages (from httpx[http2]>=0.14.0->qdrant_client) (4.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /opt/homebrew/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (0.0.4)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (0.1.1)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (0.0.72)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.9/site-packages (from dataclasses-json->llama-index) (3.20.1)\n",
            "Requirement already satisfied: click in /opt/homebrew/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.10.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.9/site-packages (from openai>=1.1.0->llama-index) (1.8.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/lib/python3.9/site-packages (from pydantic<3,>=2->trulens-eval==0.19.2) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /opt/homebrew/lib/python3.9/site-packages (from pydantic<3,>=2->trulens-eval==0.19.2) (2.14.5)\n",
            "Requirement already satisfied: six>=1.5 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.31.0->llama-index) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (5.2.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (6.11.0)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (13.7.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (6.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas->llama-index) (2023.3)\n",
            "Requirement already satisfied: python-decouple<4.0,>=3.6 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-aggrid>=0.3.4.post3->trulens-eval==0.19.2) (3.8)\n",
            "Requirement already satisfied: entrypoints>=0.4 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.4)\n",
            "Requirement already satisfied: htbuilder>=0.6.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.6.2)\n",
            "Requirement already satisfied: markdownlit>=0.0.5 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.0.7)\n",
            "Requirement already satisfied: st-annotated-text>=3.0.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (4.0.1)\n",
            "Requirement already satisfied: streamlit-camera-input-live>=0.2.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.2.0)\n",
            "Requirement already satisfied: streamlit-card>=0.0.4 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (1.0.0)\n",
            "Requirement already satisfied: streamlit-embedcode>=0.1.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.1.2)\n",
            "Requirement already satisfied: streamlit-faker>=0.0.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.0.3)\n",
            "Requirement already satisfied: streamlit-image-coordinates<0.2.0,>=0.1.1 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.1.6)\n",
            "Requirement already satisfied: streamlit-keyup>=0.1.9 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.2.2)\n",
            "Requirement already satisfied: streamlit-toggle-switch>=1.0.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (1.0.2)\n",
            "Requirement already satisfied: streamlit-vertical-slider>=1.0.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (2.0.5)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.9/site-packages (from typing-inspect>=0.8.0->trulens-eval==0.19.2) (1.0.0)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /opt/homebrew/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (4.20.0)\n",
            "Requirement already satisfied: toolz in /opt/homebrew/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (0.12.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index) (1.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/homebrew/lib/python3.9/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.27.0->trulens-eval==0.19.2) (4.0.11)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/homebrew/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai>=0.3.0) (1.60.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/homebrew/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /opt/homebrew/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client) (4.0.0)\n",
            "Requirement already satisfied: more-itertools in /opt/homebrew/lib/python3.9/site-packages (from htbuilder>=0.6.2->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (10.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.335->trulens-eval==0.19.2) (2.4)\n",
            "Requirement already satisfied: markdown in /opt/homebrew/lib/python3.9/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (3.5.1)\n",
            "Requirement already satisfied: lxml in /opt/homebrew/lib/python3.9/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (4.9.4)\n",
            "Requirement already satisfied: favicon in /opt/homebrew/lib/python3.9/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.7.0)\n",
            "Requirement already satisfied: pymdown-extensions in /opt/homebrew/lib/python3.9/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (10.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai>=0.3.0) (0.5.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit>=1.27.0->trulens-eval==0.19.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from rich<14,>=10.14.0->streamlit>=1.27.0->trulens-eval==0.19.2) (2.17.2)\n",
            "Requirement already satisfied: faker in /opt/homebrew/lib/python3.9/site-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (21.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/homebrew/lib/python3.9/site-packages (from Mako->alembic>=1.11.2->trulens-eval==0.19.2) (2.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/homebrew/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.27.0->trulens-eval==0.19.2) (5.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (0.15.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.27.0->trulens-eval==0.19.2) (0.1.2)\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install trulens-eval==0.19.2 llama-index 'google-generativeai>=0.3.0' matplotlib qdrant_client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4479bf64"
      },
      "source": [
        "##  Use Gemini to understand Images from URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5455d8c6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA8OU1vTxsI7Ox4-1ZuhW7yOZ648DVrV4U\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d0d083e"
      },
      "source": [
        "## Initialize `GeminiMultiModal` and Load Images from URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "8725b6d2",
        "outputId": "114049bb-b5c0-4cc4-9962-8d04941e3685"
      },
      "outputs": [],
      "source": [
        "from llama_index.multi_modal_llms.gemini import GeminiMultiModal\n",
        "\n",
        "from llama_index.multi_modal_llms.generic_utils import (\n",
        "    load_image_urls,\n",
        ")\n",
        "\n",
        "\n",
        "image_urls = [\n",
        "    \"https://t4.ftcdn.net/jpg/01/68/57/49/240_F_168574964_oT96d6RDgQfar4OqdljIxwl7qYdOzGfe.jpg\",\n",
        "    \"https://t3.ftcdn.net/jpg/01/76/97/96/240_F_176979696_hqfioFYq7pX13dmiu9ENrpsHZy1yM3Dt.jpg\",\n",
        "    \"https://imgur.com/a/2XlRamC\"\n",
        "]\n",
        "\n",
        "image_documents = load_image_urls(image_urls)\n",
        "\n",
        "gemini_pro = GeminiMultiModal(model_name=\"models/gemini-pro-vision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSR_1EIenId3",
        "outputId": "57d10d9d-d30c-496c-9275-2d12e10b2f95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ImageDocument(id_='f729117a-6b44-4dfb-b72c-1392bc965da4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path=None, image_url='https://t4.ftcdn.net/jpg/01/68/57/49/240_F_168574964_oT96d6RDgQfar4OqdljIxwl7qYdOzGfe.jpg', text_embedding=None),\n",
              " ImageDocument(id_='1a915e2a-e214-40f5-840b-5f09ffcf1f59', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path=None, image_url='https://t3.ftcdn.net/jpg/01/76/97/96/240_F_176979696_hqfioFYq7pX13dmiu9ENrpsHZy1yM3Dt.jpg', text_embedding=None),\n",
              " ImageDocument(id_='292c8a57-7ceb-436d-b41e-88784a3f15e7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path=None, image_url='https://imgur.com/a/2XlRamC', text_embedding=None)]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MclJbYDlnId3"
      },
      "source": [
        "## Setup TruLens Instrumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "umVGWFclnId3"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "from trulens_eval import Tru\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "from trulens_eval import Provider\n",
        "from trulens_eval import Feedback\n",
        "from trulens_eval import Select\n",
        "\n",
        "tru = Tru()\n",
        "tru.reset_database()\n",
        "\n",
        "# create a custom class to instrument\n",
        "class Gemini:\n",
        "    @instrument\n",
        "    def complete(self, prompt, image_documents):\n",
        "        completion = gemini_pro.complete(\n",
        "            prompt=prompt,\n",
        "            image_documents=image_documents,\n",
        "        )\n",
        "        return completion\n",
        "\n",
        "gemini = Gemini()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUjfY_8rnId4"
      },
      "source": [
        "## Setup custom provider with Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3gKZCFrnId4",
        "outputId": "aa02ed88-f959-4a5c-b335-ea4aade163b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… In Apple Guess Rating, input image_document will be set to __record__.calls[0].args.image_documents[0].image_url .\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# create a custom gemini feedback provider\n",
        "class Gemini_Provider(Provider):\n",
        "    def apple_guess_rating(self, image_document) -> float:\n",
        "        apple_score = float(gemini_pro.complete(prompt = \"Is the image of an apple? Respond with the float likelihood from 0.0 (not apple) to 1.0 (apple).\",\n",
        "        image_documents=[image_document]).text)\n",
        "        return apple_score\n",
        "\n",
        "gemini_provider = Gemini_Provider()\n",
        "\n",
        "f_custom_function = Feedback(gemini_provider.apple_guess_rating, name = \"Apple Guess Rating\").on(Select.Record.calls[0].args.image_documents[0].image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HMqVB6-nId4"
      },
      "source": [
        "## Test custom feedback function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "Fp_1DfDonId4",
        "outputId": "90ae244a-a6bb-4f62-afd2-71fc7ee90cf1"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'resolve_image'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Open the image\u001b[39;00m\n\u001b[1;32m     11\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\n\u001b[0;32m---> 12\u001b[0m test_confidence \u001b[38;5;241m=\u001b[39m \u001b[43mgemini_provider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapple_guess_rating\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_url \u001b[38;5;129;01min\u001b[39;00m image_urls:\n\u001b[1;32m     16\u001b[0m     confidence \u001b[38;5;241m=\u001b[39m gemini_provider\u001b[38;5;241m.\u001b[39mapple_guess_rating(image_url\u001b[38;5;241m=\u001b[39mimage_url)\n",
            "Cell \u001b[0;32mIn[34], line 4\u001b[0m, in \u001b[0;36mGemini_Provider.apple_guess_rating\u001b[0;34m(self, image_document)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapple_guess_rating\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_document) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     apple_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mgemini_pro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIs the image of an apple? Respond with the float likelihood from 0.0 (not apple) to 1.0 (apple).\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mimage_document\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apple_score\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py:159\u001b[0m, in \u001b[0;36mGeminiMultiModal.complete\u001b[0;34m(self, prompt, image_documents, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, image_documents: Sequence[ImageDocument], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[0;32m--> 159\u001b[0m     images \u001b[38;5;241m=\u001b[39m [PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(doc\u001b[38;5;241m.\u001b[39mresolve_image()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m image_documents]\n\u001b[1;32m    160\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt, \u001b[38;5;241m*\u001b[39mimages], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_from_gemini_response(result)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py:159\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, image_documents: Sequence[ImageDocument], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[0;32m--> 159\u001b[0m     images \u001b[38;5;241m=\u001b[39m [PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_image\u001b[49m()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m image_documents]\n\u001b[1;32m    160\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt, \u001b[38;5;241m*\u001b[39mimages], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_from_gemini_response(result)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'resolve_image'"
          ]
        }
      ],
      "source": [
        "import statistics\n",
        "confidence_levels = []\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# Specify the path to the image file\n",
        "image_path = \"apple_test_images/apple_21541.png\"\n",
        "\n",
        "# Open the image\n",
        "image = Image.open(image_path)\n",
        "test_confidence = gemini_provider.apple_guess_rating(image_document=image_path)\n",
        "\n",
        "\n",
        "for image_url in image_urls:\n",
        "    confidence = gemini_provider.apple_guess_rating(image_url=image_url)\n",
        "    confidence_levels.append(confidence)\n",
        "    print(f\"confidence: {confidence}\")\n",
        "\n",
        "\n",
        "print(f\"average confidence: {statistics.mean(confidence_levels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ioi8cXjnId4"
      },
      "source": [
        "## Instrument custom app with TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PDF1pGhNnId4"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "tru_gemini = TruCustomApp(gemini, app_id = \"gemini\", feedbacks = [f_custom_function])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "919wLYUTnId5"
      },
      "source": [
        "## Run the app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "fsbla0IjnId5",
        "outputId": "fe5c33b4-8412-4e63-a826-cb1da9f37d01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error calling wrapped function complete.\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py\", line 732, in wrapper\n",
            "    rets, cost = Endpoint.track_all_costs_tally(\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 447, in track_all_costs_tally\n",
            "    result, cbs = Endpoint.track_all_costs(\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 396, in track_all_costs\n",
            "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 553, in _track_costs\n",
            "    result: T = thunk()\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py\", line 733, in <lambda>\n",
            "    lambda: func(*bindings.args, **bindings.kwargs)\n",
            "  File \"/var/folders/w4/p920nxd539l9mzghrkxf765w0000gn/T/ipykernel_49892/1209908114.py\", line 15, in complete\n",
            "    completion = gemini_pro.complete(\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py\", line 159, in complete\n",
            "    images = [PIL.Image.open(doc.resolve_image()) for doc in image_documents]\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py\", line 159, in <listcomp>\n",
            "    images = [PIL.Image.open(doc.resolve_image()) for doc in image_documents]\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/PIL/Image.py\", line 3305, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x1692c2c20>\n",
            "\n",
            "Unsure what the main input string is for the call to complete with args ['Identify the city where this photo was taken.', [ImageDocument(id_='fc15f81c-6580-4dec-903f-77815e8e341b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path=None, image_url='https://storage.googleapis.com/generativeai-downloads/data/scene.jpghttps://t3.ftcdn.net/jpg/01/76/97/96/240_F_176979696_hqfioFYq7pX13dmiu9ENrpsHZy1yM3Dt.jpg', text_embedding=None)]].\n",
            "Unsure what the main output string is for the call to complete.\n"
          ]
        },
        {
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x1692c2c20>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tru_gemini \u001b[38;5;28;01mas\u001b[39;00m recording:\n\u001b[0;32m----> 2\u001b[0m     gemini\u001b[38;5;241m.\u001b[39mcomplete(\n\u001b[1;32m      3\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentify the city where this photo was taken.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     image_documents\u001b[38;5;241m=\u001b[39mimage_documents\n\u001b[1;32m      5\u001b[0m     )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print(f\"{dir(tru_gemini)}\")\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/app.py:714\u001b[0m, in \u001b[0;36mApp.__exit__\u001b[0;34m(self, exc_type, exc_value, exc_tb)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecording_contexts\u001b[38;5;241m.\u001b[39mreset(ctx\u001b[38;5;241m.\u001b[39mtoken)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tru_gemini \u001b[38;5;28;01mas\u001b[39;00m recording:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mgemini\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIdentify the city where this photo was taken.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_documents\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print(f\"{dir(tru_gemini)}\")\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py:781\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;66;03m# If stack has only 1 thing on it, we are looking at a \"root\u001b[39;00m\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;66;03m# call\". Create a record of the result and notify the app:\u001b[39;00m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stack) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    779\u001b[0m         \u001b[38;5;66;03m# If this is a root call, notify app to add the completed record\u001b[39;00m\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;66;03m# into its containers:\u001b[39;00m\n\u001b[0;32m--> 781\u001b[0m         \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_add_record\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m            \u001b[49m\u001b[43msig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mret\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mperf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPerf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcost\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/app.py:762\u001b[0m, in \u001b[0;36mApp._on_add_record\u001b[0;34m(self, ctx, func, sig, bindings, ret, error, perf, cost)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;66;03m# May block on DB.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_error(record\u001b[38;5;241m=\u001b[39mrecord, error\u001b[38;5;241m=\u001b[39merror)\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    764\u001b[0m \u001b[38;5;66;03m# Will block on DB, but not on feedback evaluation, depending on\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# FeedbackMode:\u001b[39;00m\n\u001b[1;32m    766\u001b[0m record\u001b[38;5;241m.\u001b[39mfeedback_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_record(record\u001b[38;5;241m=\u001b[39mrecord)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py:732\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 732\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs_tally\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    737\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py:447\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs_tally\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm, with_bedrock)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack_all_costs_tally\u001b[39m(\n\u001b[1;32m    435\u001b[0m     thunk: Thunk[T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[T, Cost]:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# TODO: dedup async/sync\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    Track costs of all of the apis we can currently track, over the\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    execution of thunk.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     result, cbs \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_openai\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_openai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_hugs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_hugs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_litellm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_litellm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_bedrock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_bedrock\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cbs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;66;03m# Otherwise sum returns \"0\" below.\u001b[39;00m\n\u001b[1;32m    457\u001b[0m         costs \u001b[38;5;241m=\u001b[39m Cost()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py:396\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm, with_bedrock)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    390\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    391\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not initiallize endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPossibly missing key(s). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrulens_eval will not track costs/usage of this endpoint. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    394\u001b[0m             )\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_costs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_endpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py:553\u001b[0m, in \u001b[0;36mEndpoint._track_costs\u001b[0;34m(thunk, with_endpoints)\u001b[0m\n\u001b[1;32m    550\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(callback)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# Call the thunk.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m result: T \u001b[38;5;241m=\u001b[39m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# Return result and only the callbacks created here. Outer thunks might\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# return others.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, callbacks\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py:733\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    732\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m Endpoint\u001b[38;5;241m.\u001b[39mtrack_all_costs_tally(\n\u001b[0;32m--> 733\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m     )\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    737\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
            "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mGemini.complete\u001b[0;34m(self, prompt, image_documents)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@instrument\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt, image_documents):\n\u001b[0;32m---> 15\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mgemini_pro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py:159\u001b[0m, in \u001b[0;36mGeminiMultiModal.complete\u001b[0;34m(self, prompt, image_documents, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, image_documents: Sequence[ImageDocument], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[0;32m--> 159\u001b[0m     images \u001b[38;5;241m=\u001b[39m [PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(doc\u001b[38;5;241m.\u001b[39mresolve_image()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m image_documents]\n\u001b[1;32m    160\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt, \u001b[38;5;241m*\u001b[39mimages], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_from_gemini_response(result)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py:159\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, image_documents: Sequence[ImageDocument], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[0;32m--> 159\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m image_documents]\n\u001b[1;32m    160\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt, \u001b[38;5;241m*\u001b[39mimages], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_from_gemini_response(result)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/PIL/Image.py:3305\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3303\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3304\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3305\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x1692c2c20>"
          ]
        }
      ],
      "source": [
        "with tru_gemini as recording:\n",
        "    gemini.complete(\n",
        "    prompt=\"Identify the city where this photo was taken.\",\n",
        "    image_documents=image_documents\n",
        "    )\n",
        "\n",
        "#print(f\"{dir(tru_gemini)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyR5IYXyRfaa"
      },
      "source": [
        "## Build Multi-Modal RAG for Restaurant Recommendation\n",
        "\n",
        "Our stack consists of TruLens + Gemini + LlamaIndex + Pydantic structured output capabilities.\n",
        "\n",
        "Pydantic structured output is great,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H33LK17nId5"
      },
      "source": [
        "### Download data to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCCX9AEenId5",
        "outputId": "53c0eee1-3864-47d2-a7c4-29835ae6aaa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "input_image_path = Path(\"google_restaurants\")\n",
        "if not input_image_path.exists():\n",
        "    Path.mkdir(input_image_path)\n",
        "\n",
        "!wget \"https://docs.google.com/uc?export=download&id=1Pg04p6ss0FlBgz00noHAOAJ1EYXiosKg\" -O ./google_restaurants/miami.png\n",
        "!wget \"https://docs.google.com/uc?export=download&id=1dYZy17bD6pSsEyACXx9fRMNx93ok-kTJ\" -O ./google_restaurants/orlando.png\n",
        "!wget \"https://docs.google.com/uc?export=download&id=1ShPnYVc1iL_TA1t7ErCFEAHT74-qvMrn\" -O ./google_restaurants/sf.png\n",
        "!wget \"https://docs.google.com/uc?export=download&id=1WjISWnatHjwL4z5VD_9o09ORWhRJuYqm\" -O ./google_restaurants/toronto.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJVO9lNDnId5"
      },
      "source": [
        "### Define Pydantic Class for Strucutred Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cNol-nemnId5"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './google_restaurants/miami.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m     nearby_tourist_places: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m     21\u001b[0m google_image_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./google_restaurants/miami.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoogle_image_url\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/PIL/Image.py:3243\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3240\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3243\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3244\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './google_restaurants/miami.png'"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class GoogleRestaurant(BaseModel):\n",
        "    \"\"\"Data model for a Google Restaurant.\"\"\"\n",
        "\n",
        "    restaurant: str\n",
        "    food: str\n",
        "    location: str\n",
        "    category: str\n",
        "    hours: str\n",
        "    price: str\n",
        "    rating: float\n",
        "    review: str\n",
        "    description: str\n",
        "    nearby_tourist_places: str\n",
        "\n",
        "\n",
        "google_image_url = \"./google_restaurants/miami.png\"\n",
        "image = Image.open(google_image_url).convert(\"RGB\")\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT0wZY2knId5"
      },
      "outputs": [],
      "source": [
        "from llama_index.multi_modal_llms import GeminiMultiModal\n",
        "from llama_index.program import MultiModalLLMCompletionProgram\n",
        "from llama_index.output_parsers import PydanticOutputParser\n",
        "\n",
        "prompt_template_str = \"\"\"\\\n",
        "    can you summarize what is in the image\\\n",
        "    and return the answer with json format \\\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def pydantic_gemini(\n",
        "    model_name, output_class, image_documents, prompt_template_str\n",
        "):\n",
        "    gemini_llm = GeminiMultiModal(\n",
        "        api_key=os.environ[\"GOOGLE_API_KEY\"], model_name=model_name\n",
        "    )\n",
        "\n",
        "    llm_program = MultiModalLLMCompletionProgram.from_defaults(\n",
        "        output_parser=PydanticOutputParser(output_class),\n",
        "        image_documents=image_documents,\n",
        "        prompt_template_str=prompt_template_str,\n",
        "        multi_modal_llm=gemini_llm,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    response = llm_program()\n",
        "    return response\n",
        "\n",
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "google_image_documents = SimpleDirectoryReader(\n",
        "    \"./google_restaurants\"\n",
        ").load_data()\n",
        "\n",
        "results = []\n",
        "for img_doc in google_image_documents:\n",
        "    pydantic_response = pydantic_gemini(\n",
        "        \"models/gemini-pro-vision\",\n",
        "        GoogleRestaurant,\n",
        "        [img_doc],\n",
        "        prompt_template_str,\n",
        "    )\n",
        "    # only output the results for miami for example along with image\n",
        "    if \"miami\" in img_doc.image_path:\n",
        "        for r in pydantic_response:\n",
        "            print(r)\n",
        "    results.append(pydantic_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZWjzsSkRfaa"
      },
      "source": [
        "### Construct Text Nodes for Building Vector Store. Store metadata and description for each restaurant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBcrWwGYRfaa"
      },
      "outputs": [],
      "source": [
        "from llama_index.schema import TextNode\n",
        "\n",
        "nodes = []\n",
        "for res in results:\n",
        "    text_node = TextNode()\n",
        "    metadata = {}\n",
        "    for r in res:\n",
        "        # set description as text of TextNode\n",
        "        if r[0] == \"description\":\n",
        "            text_node.text = r[1]\n",
        "        else:\n",
        "            metadata[r[0]] = r[1]\n",
        "    text_node.metadata = metadata\n",
        "    nodes.append(text_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrDnWgtbRfah"
      },
      "source": [
        "### Using Gemini Embedding for building Vector Store for Dense retrieval. Index Restaurants as nodes into Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ueV_FenRfah"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex, StorageContext, ServiceContext\n",
        "from llama_index.embeddings import GeminiEmbedding\n",
        "from llama_index.llms import Gemini\n",
        "from llama_index.vector_stores import QdrantVectorStore\n",
        "from llama_index import StorageContext\n",
        "import qdrant_client\n",
        "\n",
        "# Create a local Qdrant vector store\n",
        "client = qdrant_client.QdrantClient(path=\"qdrant_gemini_4\")\n",
        "\n",
        "vector_store = QdrantVectorStore(client=client, collection_name=\"collection\")\n",
        "\n",
        "# Using the embedding model to Gemini\n",
        "embed_model = GeminiEmbedding(\n",
        "    model_name=\"models/embedding-001\", api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
        ")\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=Gemini(), embed_model=embed_model\n",
        ")\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex(\n",
        "    nodes=nodes,\n",
        "    service_context=service_context,\n",
        "    storage_context=storage_context,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geZEOLcaRfah"
      },
      "source": [
        "### Using Gemini to synthesize the results and recommend the restaurants to user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmYNzEOCRfah"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=1,\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"recommend an inexpensive Orlando restaurant for me and its nearby tourist places\"\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYsRAvBlnId7"
      },
      "source": [
        "## Instrument and Evaluate `query_engine` with TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W71pyCPTnId8"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms import Gemini\n",
        "\n",
        "from trulens_eval import Provider\n",
        "from trulens_eval import Feedback\n",
        "from trulens_eval import Select\n",
        "\n",
        "from trulens_eval import LiteLLM\n",
        "from google.cloud import aiplatform\n",
        "aiplatform.init(\n",
        "    project = \"trulens-testing\",\n",
        "    location=\"us-central1\"\n",
        ")\n",
        "\n",
        "gemini_provider = LiteLLM(model_engine=\"gemini-pro\")\n",
        "\n",
        "from trulens_eval.feedback import Groundedness\n",
        "import numpy as np\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=gemini_provider)\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
        "    .on(Select.RecordCalls._response_synthesizer.get_response.args.text_chunks[0].collect())\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = (\n",
        "    Feedback(gemini_provider.relevance, name = \"Answer Relevance\")\n",
        "    .on_input()\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(gemini_provider.qs_relevance, name = \"Context Relevance\")\n",
        "    .on_input()\n",
        "    .on(Select.RecordCalls._response_synthesizer.get_response.args.text_chunks[0])\n",
        "    .aggregate(np.mean)\n",
        ")\n",
        "\n",
        "import re\n",
        "gemini_text = Gemini()\n",
        "\n",
        "# create a custom gemini feedback provider to rate affordability. Do it with len() and math and also with an LLM.\n",
        "class Gemini_Provider(Provider):\n",
        "    def affordable_math(self, text: str) -> float:\n",
        "        \"\"\"\n",
        "        Count the number of money signs using len(). Then subtract 1 and divide by 3.\n",
        "        \"\"\"\n",
        "        affordability = 1 - (\n",
        "            (len(text) - 1)/3)\n",
        "        return affordability\n",
        "\n",
        "    def affordable_llm(self, text: str) -> float:\n",
        "        \"\"\"\n",
        "        Count the number of money signs using an LLM. Then subtract 1 and take the reciprocal.\n",
        "        \"\"\"\n",
        "        prompt = f\"Count the number of characters in the text: {text}. Then subtract 1 and divide the result by 3. Last subtract from 1. Final answer:\"\n",
        "        gemini_response = gemini_text.complete(prompt).text\n",
        "        # gemini is a bit verbose, so do some regex to get the answer out.\n",
        "        float_pattern = r'[-+]?\\d*\\.\\d+|\\d+'\n",
        "        float_numbers = re.findall(float_pattern, gemini_response)\n",
        "        rightmost_float = float(float_numbers[-1])\n",
        "        affordability = rightmost_float\n",
        "        return affordability\n",
        "\n",
        "gemini_provider_custom = Gemini_Provider()\n",
        "f_affordable_math = Feedback(gemini_provider_custom.affordable_math, name = \"Affordability - Math\").on(Select.RecordCalls.retriever._index.storage_context.vector_stores.default.query.rets.nodes[0].metadata.price)\n",
        "f_affordable_llm = Feedback(gemini_provider_custom.affordable_llm, name = \"Affordability - LLM\").on(Select.RecordCalls.retriever._index.storage_context.vector_stores.default.query.rets.nodes[0].metadata.price)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEDKkdv_nId8"
      },
      "source": [
        "### Test the feedback function(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyDqriGanId8"
      },
      "outputs": [],
      "source": [
        "grounded.groundedness_measure_with_cot_reasons([\"\"\"('restaurant', 'La Mar by Gaston Acurio')\n",
        "('food', 'South American')\n",
        "('location', '500 Brickell Key Dr, Miami, FL 33131')\n",
        "('category', 'Restaurant')\n",
        "('hours', 'Open â‹… Closes 11 PM')\n",
        "('price', 'Moderate')\n",
        "('rating', 4.4)\n",
        "('review', '4.4 (2,104)')\n",
        "('description', 'Chic waterfront find offering Peruvian & fusion fare, plus bars for cocktails, ceviche & anticucho.')\n",
        "('nearby_tourist_places', 'Brickell Key Park')\"\"\"], \"La Mar by Gaston Acurio is a delicious peruvian restaurant by the water\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs0UJwNynId8"
      },
      "outputs": [],
      "source": [
        "gemini_provider.qs_relevance(\"I'm hungry for Peruvian, and would love to eat by the water. Can you recommend a dinner spot?\",\n",
        "\"\"\"('restaurant', 'La Mar by Gaston Acurio')\n",
        "('food', 'South American')\n",
        "('location', '500 Brickell Key Dr, Miami, FL 33131')\n",
        "('category', 'Restaurant')\n",
        "('hours', 'Open â‹… Closes 11 PM')\n",
        "('price', 'Moderate')\n",
        "('rating', 4.4)\n",
        "('review', '4.4 (2,104)')\n",
        "('description', 'Chic waterfront find offering Peruvian & fusion fare, plus bars for cocktails, ceviche & anticucho.')\n",
        "('nearby_tourist_places', 'Brickell Key Park')\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2byozgOmnId9"
      },
      "outputs": [],
      "source": [
        "gemini_provider.relevance(\"I'm hungry for Peruvian, and would love to eat by the water. Can you recommend a dinner spot?\",\n",
        "\"La Mar by Gaston Acurio is a delicious peruvian restaurant by the water\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFnYcV-QnId9"
      },
      "outputs": [],
      "source": [
        "gemini_provider_custom.affordable_math(\"$$\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfN42riRnId9"
      },
      "outputs": [],
      "source": [
        "gemini_provider_custom.affordable_llm(\"$$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVhHfOXinId9"
      },
      "source": [
        "### Set up instrumentation and eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD8Brkn4nId9"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruLlama\n",
        "\n",
        "tru_query_engine_recorder = TruLlama(query_engine,\n",
        "    app_id='LlamaIndex_App1',\n",
        "    feedbacks = [f_affordable_math, f_affordable_llm, f_context_relevance, f_groundedness, f_qa_relevance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4MUPZoynId-"
      },
      "outputs": [],
      "source": [
        "tru.stop_dashboard(force=True)\n",
        "tru.run_dashboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU1E0gVOnId-"
      },
      "source": [
        "### Run the app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm8S86PVnId_"
      },
      "outputs": [],
      "source": [
        "with tru_query_engine_recorder as recording:\n",
        "    query_engine.query(\"recommend an american restaurant in Orlando for me and its nearby tourist places\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4Y4p9nwnId_"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import Tru\n",
        "\n",
        "tru = Tru()\n",
        "tru.run_dashboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOClS6zXnId_"
      },
      "outputs": [],
      "source": [
        "tru.get_leaderboard(app_ids=['LlamaIndex_App1'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
