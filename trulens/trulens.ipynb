{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "368686b4-f487-4dd4-aeff-37823976529d"
      },
      "source": [
        "# Geminize Trulens Custom Feedback Function\n",
        "\n",
        "We created a game where two players are given a word to draw and a canvas. The two players then race against each other to draw the word well enough to where the AI model (Gemini Pro) guesses that same word when asked \"What is this an object of? Give a one word answer.\" Whoever sends an image where the AI guesses correctly is the winner.\n",
        "\n",
        "To gauge Gemini Pro's ability to recognize certain words, we tested it on images of \"apple\" drawings chosen by our team as potential winners. We asked the model if each image depicted an apple and recorded its confidence level. Analyzing the average confidence across this dataset lets us evaluate how well our model performs. This analysis used a custom feedback function from Trulens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc691ca8",
        "outputId": "effa88c9-e035-4502-8e7c-550e5e292873"
      },
      "outputs": [],
      "source": [
        "%pip install trulens-eval==0.19.2 llama-index google-generativeai>=0.3.0 matplotlib qdrant_client Ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5455d8c6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d0d083e"
      },
      "source": [
        "## Initialize Model and Load Images from URLs\n",
        "\n",
        "Here we collect our dataset of apple drawings. The images are also stored in this repo in the folder 'apple_test_images'. There are two image urls of real apples that were helpful during testing the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "8725b6d2",
        "outputId": "114049bb-b5c0-4cc4-9962-8d04941e3685"
      },
      "outputs": [],
      "source": [
        "from llama_index.multi_modal_llms.gemini import GeminiMultiModal\n",
        "\n",
        "from llama_index.multi_modal_llms.generic_utils import (\n",
        "    load_image_urls,\n",
        ")\n",
        "\n",
        "REAL_APPLE_IMAGE = \"https://t4.ftcdn.net/jpg/01/68/57/49/240_F_168574964_oT96d6RDgQfar4OqdljIxwl7qYdOzGfe.jpg\"\n",
        "REAL_APPLE_IMAGE_2 =  \"https://t3.ftcdn.net/jpg/01/76/97/96/240_F_176979696_hqfioFYq7pX13dmiu9ENrpsHZy1yM3Dt.jpg\"\n",
        "\n",
        "image_urls = [\n",
        "    \"https://i.imgur.com/48MZGWM.png\",\n",
        "    \"https://i.imgur.com/gj7xoIz.png\",\n",
        "    \"https://i.imgur.com/dn2p2mh.png\",\n",
        "    \"https://i.imgur.com/CXrtEV7.png\",\n",
        "    \"https://i.imgur.com/VkaBMhF.png\",\n",
        "    \"https://i.imgur.com/MQLkY89.png\",\n",
        "    \"https://i.imgur.com/Q7MmZvC.png\",\n",
        "    \"https://i.imgur.com/PPPxgsX.png\",\n",
        "    \"https://i.imgur.com/JuYydqX.png\",\n",
        "    \"https://i.imgur.com/xxqX440.png\"\n",
        "]\n",
        "\n",
        "image_documents = load_image_urls(image_urls)\n",
        "\n",
        "gemini_pro = GeminiMultiModal(model_name=\"models/gemini-pro-vision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MclJbYDlnId3"
      },
      "source": [
        "## Setup TruLens Instrumentation\n",
        "\n",
        "We set up our Tru instance and the model we are using (Gemini Pro)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "umVGWFclnId3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
            "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "from trulens_eval import Tru\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "from trulens_eval import Provider\n",
        "from trulens_eval import Feedback\n",
        "from trulens_eval import Select\n",
        "\n",
        "tru = Tru()\n",
        "tru.reset_database()\n",
        "\n",
        "# create a custom class to instrument\n",
        "class Gemini:\n",
        "    @instrument\n",
        "    def complete(self, prompt, image_documents):\n",
        "        completion = gemini_pro.complete(\n",
        "            prompt=prompt,\n",
        "            image_documents=image_documents,\n",
        "        )\n",
        "        return completion\n",
        "\n",
        "gemini = Gemini()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUjfY_8rnId4"
      },
      "source": [
        "## Setup Trulens Custom Provider with Gemini\n",
        "\n",
        "Here we create a Trulens custom feedback function for evaluating if the model can guess correct drawings of one of our words: apple. We ask it specifically if the image is an apple, and the likelihood represented by a probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3gKZCFrnId4",
        "outputId": "aa02ed88-f959-4a5c-b335-ea4aade163b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… In Apple Guess Rating, input image_url will be set to __record__.calls[0].args.image_documents[0].image_url .\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# create a custom gemini feedback provider\n",
        "class Gemini_Provider(Provider):\n",
        "    def apple_guess_rating(self, image_url) -> float:\n",
        "        image_documents = load_image_urls([image_url])\n",
        "        apple_score = float(gemini_pro.complete(prompt = \"Is the image of an apple? Respond with the float likelihood from 0.00 (not apple) to 1.00 (apple).\",\n",
        "        image_documents=image_documents).text)\n",
        "        return apple_score\n",
        "\n",
        "gemini_provider = Gemini_Provider()\n",
        "\n",
        "f_custom_function = Feedback(gemini_provider.apple_guess_rating, name = \"Apple Guess Rating\").on(Select.Record.calls[0].args.image_documents[0].image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HMqVB6-nId4"
      },
      "source": [
        "## Evaluate Model\n",
        "\n",
        "We can use our TruLens custom feedback function on these 10 test images to see how well the model is performing at guessing drawings. The team deemed these as worthy of a win, so let's see how confident the model is on these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "Fp_1DfDonId4",
        "outputId": "90ae244a-a6bb-4f62-afd2-71fc7ee90cf1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/48MZGWM.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.9\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/gj7xoIz.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.99\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/dn2p2mh.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.99\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/CXrtEV7.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.99\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/VkaBMhF.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.95\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/MQLkY89.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.9\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/Q7MmZvC.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.99\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/PPPxgsX.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.99\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/JuYydqX.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.9\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/xxqX440.png\" width=\"100\" height=\"100\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confidence: 0.9\n",
            "\n",
            "\n",
            "average confidence: 0.95\n"
          ]
        }
      ],
      "source": [
        "import statistics\n",
        "\n",
        "confidence_levels = []\n",
        "\n",
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "for image_url in image_urls:\n",
        "    #display the image\n",
        "    display(Image(url=image_url, width=100, height=100))\n",
        "\n",
        "    # print the confidence for the image\n",
        "    confidence = gemini_provider.apple_guess_rating(image_url=image_url)\n",
        "    confidence_levels.append(confidence)\n",
        "    print(f\"confidence: {confidence}\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    \n",
        "\n",
        "print(f\"average confidence: {statistics.mean(confidence_levels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wrapping Up/Next Steps\n",
        "\n",
        "We were able to see that our model is highly accurate at guessing these drawings. Because of our time constraints, we had to work with a smaller dataset for this exercise. If we were to scale this application in the cloud, we could capture and store successful drawings from our player community and create a test set out of those."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
