{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "368686b4-f487-4dd4-aeff-37823976529d"
      },
      "source": [
        "# Evaluate Multi-Modal LLM using Google's Gemini model for image understanding and multi-modal RAG\n",
        "\n",
        "In the first example, run and evaluate a multimodal Gemini model with a multimodal evaluator.\n",
        "\n",
        "In the second example, learn how to run semantic evaluations on a multi-modal RAG, including the RAG triad.\n",
        "\n",
        "Note: `google-generativeai` is only available for certain countries and regions. Original example attribution: Llama-Index\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/models/gemini_multi_modal.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc691ca8",
        "outputId": "effa88c9-e035-4502-8e7c-550e5e292873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: trulens-eval==0.19.2 in /opt/homebrew/lib/python3.9/site-packages (0.19.2)\n",
            "Requirement already satisfied: llama-index in /opt/homebrew/lib/python3.9/site-packages (0.9.17)\n",
            "Requirement already satisfied: google-generativeai>=0.3.0 in /opt/homebrew/lib/python3.9/site-packages (0.3.1)\n",
            "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.9/site-packages (3.8.2)\n",
            "Requirement already satisfied: qdrant_client in /opt/homebrew/lib/python3.9/site-packages (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.26.2)\n",
            "Requirement already satisfied: frozendict>=2.3.8 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (2.3.10)\n",
            "Requirement already satisfied: munch>=3.0.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (4.0.0)\n",
            "Requirement already satisfied: dill>=0.3.7 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.3.7)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.0.0)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (2.5.2)\n",
            "Requirement already satisfied: merkle-json>=1.0.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.0.0)\n",
            "Requirement already satisfied: langchain>=0.0.335 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.0.351)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from trulens-eval==0.19.2) (4.9.0)\n",
            "Requirement already satisfied: millify>=0.1.1 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.1.1)\n",
            "Requirement already satisfied: humanize>=4.6.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (4.9.0)\n",
            "Requirement already satisfied: streamlit>=1.27.0 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.29.0)\n",
            "Requirement already satisfied: streamlit-aggrid>=0.3.4.post3 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.3.4.post3)\n",
            "Requirement already satisfied: streamlit-extras>=0.2.7 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (0.3.6)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.19 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (2.0.23)\n",
            "Requirement already satisfied: alembic>=1.11.2 in /opt/homebrew/lib/python3.9/site-packages (from trulens-eval==0.19.2) (1.13.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (4.12.2)\n",
            "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (1.2.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (2023.12.2)\n",
            "Requirement already satisfied: httpx in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (0.25.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (1.6.0)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.31.0 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.9/site-packages (from llama-index) (0.5.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (2.25.2)\n",
            "Requirement already satisfied: google-api-core in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (2.15.0)\n",
            "Requirement already satisfied: protobuf in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (4.25.1)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.9/site-packages (from google-generativeai>=0.3.0) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/homebrew/lib/python3.9/site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai>=0.3.0) (1.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /opt/homebrew/lib/python3.9/site-packages (from qdrant_client) (1.60.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /opt/homebrew/lib/python3.9/site-packages (from qdrant_client) (1.60.0)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /opt/homebrew/lib/python3.9/site-packages (from qdrant_client) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.14 in /opt/homebrew/lib/python3.9/site-packages (from qdrant_client) (1.26.18)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n",
            "Requirement already satisfied: Mako in /opt/homebrew/lib/python3.9/site-packages (from alembic>=1.11.2->trulens-eval==0.19.2) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /opt/homebrew/lib/python3.9/site-packages (from deprecated>=1.2.9.3->llama-index) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/homebrew/lib/python3.9/site-packages (from google-api-core->google-generativeai>=0.3.0) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from google-auth->google-generativeai>=0.3.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/lib/python3.9/site-packages (from google-auth->google-generativeai>=0.3.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/lib/python3.9/site-packages (from google-auth->google-generativeai>=0.3.0) (4.9)\n",
            "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.9/site-packages (from grpcio-tools>=1.41.0->qdrant_client) (60.10.0)\n",
            "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (4.2.0)\n",
            "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (1.0.2)\n",
            "Requirement already satisfied: idna in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (3.6)\n",
            "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.9/site-packages (from httpx->llama-index) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /opt/homebrew/lib/python3.9/site-packages (from httpx[http2]>=0.14.0->qdrant_client) (4.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /opt/homebrew/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (0.0.4)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (0.1.1)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in /opt/homebrew/lib/python3.9/site-packages (from langchain>=0.0.335->trulens-eval==0.19.2) (0.0.72)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.9/site-packages (from dataclasses-json->llama-index) (3.20.1)\n",
            "Requirement already satisfied: click in /opt/homebrew/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.9/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.10.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.9/site-packages (from openai>=1.1.0->llama-index) (1.8.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/lib/python3.9/site-packages (from pydantic<3,>=2->trulens-eval==0.19.2) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /opt/homebrew/lib/python3.9/site-packages (from pydantic<3,>=2->trulens-eval==0.19.2) (2.14.5)\n",
            "Requirement already satisfied: six>=1.5 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.31.0->llama-index) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (5.2.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (6.11.0)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (13.7.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/homebrew/lib/python3.9/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from streamlit>=1.27.0->trulens-eval==0.19.2) (6.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas->llama-index) (2023.3)\n",
            "Requirement already satisfied: python-decouple<4.0,>=3.6 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-aggrid>=0.3.4.post3->trulens-eval==0.19.2) (3.8)\n",
            "Requirement already satisfied: entrypoints>=0.4 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.4)\n",
            "Requirement already satisfied: htbuilder>=0.6.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.6.2)\n",
            "Requirement already satisfied: markdownlit>=0.0.5 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.0.7)\n",
            "Requirement already satisfied: st-annotated-text>=3.0.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (4.0.1)\n",
            "Requirement already satisfied: streamlit-camera-input-live>=0.2.0 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.2.0)\n",
            "Requirement already satisfied: streamlit-card>=0.0.4 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (1.0.0)\n",
            "Requirement already satisfied: streamlit-embedcode>=0.1.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.1.2)\n",
            "Requirement already satisfied: streamlit-faker>=0.0.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.0.3)\n",
            "Requirement already satisfied: streamlit-image-coordinates<0.2.0,>=0.1.1 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.1.6)\n",
            "Requirement already satisfied: streamlit-keyup>=0.1.9 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.2.2)\n",
            "Requirement already satisfied: streamlit-toggle-switch>=1.0.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (1.0.2)\n",
            "Requirement already satisfied: streamlit-vertical-slider>=1.0.2 in /opt/homebrew/lib/python3.9/site-packages (from streamlit-extras>=0.2.7->trulens-eval==0.19.2) (2.0.5)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.9/site-packages (from typing-inspect>=0.8.0->trulens-eval==0.19.2) (1.0.0)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /opt/homebrew/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (4.20.0)\n",
            "Requirement already satisfied: toolz in /opt/homebrew/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (0.12.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index) (1.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/homebrew/lib/python3.9/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.27.0->trulens-eval==0.19.2) (4.0.11)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/homebrew/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai>=0.3.0) (1.60.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/homebrew/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /opt/homebrew/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant_client) (4.0.0)\n",
            "Requirement already satisfied: more-itertools in /opt/homebrew/lib/python3.9/site-packages (from htbuilder>=0.6.2->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (10.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.335->trulens-eval==0.19.2) (2.4)\n",
            "Requirement already satisfied: markdown in /opt/homebrew/lib/python3.9/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (3.5.1)\n",
            "Requirement already satisfied: lxml in /opt/homebrew/lib/python3.9/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (4.9.4)\n",
            "Requirement already satisfied: favicon in /opt/homebrew/lib/python3.9/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (0.7.0)\n",
            "Requirement already satisfied: pymdown-extensions in /opt/homebrew/lib/python3.9/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (10.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai>=0.3.0) (0.5.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit>=1.27.0->trulens-eval==0.19.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/seanwolfe/Library/Python/3.9/lib/python/site-packages (from rich<14,>=10.14.0->streamlit>=1.27.0->trulens-eval==0.19.2) (2.17.2)\n",
            "Requirement already satisfied: faker in /opt/homebrew/lib/python3.9/site-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.2.7->trulens-eval==0.19.2) (21.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/homebrew/lib/python3.9/site-packages (from Mako->alembic>=1.11.2->trulens-eval==0.19.2) (2.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/homebrew/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.27.0->trulens-eval==0.19.2) (5.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.27.0->trulens-eval==0.19.2) (0.15.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.27.0->trulens-eval==0.19.2) (0.1.2)\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install trulens-eval==0.19.2 llama-index 'google-generativeai>=0.3.0' matplotlib qdrant_client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4479bf64"
      },
      "source": [
        "##  Use Gemini to understand Images from URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5455d8c6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA8OU1vTxsI7Ox4-1ZuhW7yOZ648DVrV4U\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d0d083e"
      },
      "source": [
        "## Initialize `GeminiMultiModal` and Load Images from URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "8725b6d2",
        "outputId": "114049bb-b5c0-4cc4-9962-8d04941e3685"
      },
      "outputs": [],
      "source": [
        "from llama_index.multi_modal_llms.gemini import GeminiMultiModal\n",
        "\n",
        "from llama_index.multi_modal_llms.generic_utils import (\n",
        "    load_image_urls,\n",
        ")\n",
        "\n",
        "\n",
        "image_urls = [\n",
        "    \"https://t4.ftcdn.net/jpg/01/68/57/49/240_F_168574964_oT96d6RDgQfar4OqdljIxwl7qYdOzGfe.jpg\",\n",
        "    \"https://t3.ftcdn.net/jpg/01/76/97/96/240_F_176979696_hqfioFYq7pX13dmiu9ENrpsHZy1yM3Dt.jpg\",\n",
        "    \"https://imgur.com/a/2XlRamC\"\n",
        "]\n",
        "\n",
        "image_documents = load_image_urls(image_urls)\n",
        "\n",
        "gemini_pro = GeminiMultiModal(model_name=\"models/gemini-pro-vision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSR_1EIenId3",
        "outputId": "57d10d9d-d30c-496c-9275-2d12e10b2f95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ImageDocument(id_='f729117a-6b44-4dfb-b72c-1392bc965da4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path=None, image_url='https://t4.ftcdn.net/jpg/01/68/57/49/240_F_168574964_oT96d6RDgQfar4OqdljIxwl7qYdOzGfe.jpg', text_embedding=None),\n",
              " ImageDocument(id_='1a915e2a-e214-40f5-840b-5f09ffcf1f59', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path=None, image_url='https://t3.ftcdn.net/jpg/01/76/97/96/240_F_176979696_hqfioFYq7pX13dmiu9ENrpsHZy1yM3Dt.jpg', text_embedding=None),\n",
              " ImageDocument(id_='292c8a57-7ceb-436d-b41e-88784a3f15e7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path=None, image_url='https://imgur.com/a/2XlRamC', text_embedding=None)]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MclJbYDlnId3"
      },
      "source": [
        "## Setup TruLens Instrumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "umVGWFclnId3"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "from trulens_eval import Tru\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "from trulens_eval import Provider\n",
        "from trulens_eval import Feedback\n",
        "from trulens_eval import Select\n",
        "\n",
        "tru = Tru()\n",
        "tru.reset_database()\n",
        "\n",
        "# create a custom class to instrument\n",
        "class Gemini:\n",
        "    @instrument\n",
        "    def complete(self, prompt, image_documents):\n",
        "        completion = gemini_pro.complete(\n",
        "            prompt=prompt,\n",
        "            image_documents=image_documents,\n",
        "        )\n",
        "        return completion\n",
        "\n",
        "gemini = Gemini()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUjfY_8rnId4"
      },
      "source": [
        "## Setup custom provider with Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3gKZCFrnId4",
        "outputId": "aa02ed88-f959-4a5c-b335-ea4aade163b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ In Apple Guess Rating, input image_document will be set to __record__.calls[0].args.image_documents[0].image_url .\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# create a custom gemini feedback provider\n",
        "class Gemini_Provider(Provider):\n",
        "    def apple_guess_rating(self, image_document) -> float:\n",
        "        apple_score = float(gemini_pro.complete(prompt = \"Is the image of an apple? Respond with the float likelihood from 0.0 (not apple) to 1.0 (apple).\",\n",
        "        image_documents=[image_document]).text)\n",
        "        return apple_score\n",
        "\n",
        "gemini_provider = Gemini_Provider()\n",
        "\n",
        "f_custom_function = Feedback(gemini_provider.apple_guess_rating, name = \"Apple Guess Rating\").on(Select.Record.calls[0].args.image_documents[0].image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HMqVB6-nId4"
      },
      "source": [
        "## Test custom feedback function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "Fp_1DfDonId4",
        "outputId": "90ae244a-a6bb-4f62-afd2-71fc7ee90cf1"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'resolve_image'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Open the image\u001b[39;00m\n\u001b[1;32m     11\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\n\u001b[0;32m---> 12\u001b[0m test_confidence \u001b[38;5;241m=\u001b[39m \u001b[43mgemini_provider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapple_guess_rating\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_url \u001b[38;5;129;01min\u001b[39;00m image_urls:\n\u001b[1;32m     16\u001b[0m     confidence \u001b[38;5;241m=\u001b[39m gemini_provider\u001b[38;5;241m.\u001b[39mapple_guess_rating(image_url\u001b[38;5;241m=\u001b[39mimage_url)\n",
            "Cell \u001b[0;32mIn[34], line 4\u001b[0m, in \u001b[0;36mGemini_Provider.apple_guess_rating\u001b[0;34m(self, image_document)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapple_guess_rating\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_document) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     apple_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mgemini_pro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIs the image of an apple? Respond with the float likelihood from 0.0 (not apple) to 1.0 (apple).\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mimage_document\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apple_score\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py:159\u001b[0m, in \u001b[0;36mGeminiMultiModal.complete\u001b[0;34m(self, prompt, image_documents, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, image_documents: Sequence[ImageDocument], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[0;32m--> 159\u001b[0m     images \u001b[38;5;241m=\u001b[39m [PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(doc\u001b[38;5;241m.\u001b[39mresolve_image()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m image_documents]\n\u001b[1;32m    160\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt, \u001b[38;5;241m*\u001b[39mimages], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_from_gemini_response(result)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py:159\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, image_documents: Sequence[ImageDocument], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[0;32m--> 159\u001b[0m     images \u001b[38;5;241m=\u001b[39m [PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_image\u001b[49m()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m image_documents]\n\u001b[1;32m    160\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt, \u001b[38;5;241m*\u001b[39mimages], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_from_gemini_response(result)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'resolve_image'"
          ]
        }
      ],
      "source": [
        "import statistics\n",
        "confidence_levels = []\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# Specify the path to the image file\n",
        "image_path = \"apple_test_images/apple_21541.png\"\n",
        "\n",
        "# Open the image\n",
        "image = Image.open(image_path)\n",
        "test_confidence = gemini_provider.apple_guess_rating(image_document=image_path)\n",
        "\n",
        "\n",
        "for image_url in image_urls:\n",
        "    confidence = gemini_provider.apple_guess_rating(image_url=image_url)\n",
        "    confidence_levels.append(confidence)\n",
        "    print(f\"confidence: {confidence}\")\n",
        "\n",
        "\n",
        "print(f\"average confidence: {statistics.mean(confidence_levels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ioi8cXjnId4"
      },
      "source": [
        "## Instrument custom app with TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PDF1pGhNnId4"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "tru_gemini = TruCustomApp(gemini, app_id = \"gemini\", feedbacks = [f_custom_function])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "919wLYUTnId5"
      },
      "source": [
        "## Run the app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "fsbla0IjnId5",
        "outputId": "fe5c33b4-8412-4e63-a826-cb1da9f37d01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error calling wrapped function complete.\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py\", line 732, in wrapper\n",
            "    rets, cost = Endpoint.track_all_costs_tally(\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 447, in track_all_costs_tally\n",
            "    result, cbs = Endpoint.track_all_costs(\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 396, in track_all_costs\n",
            "    return Endpoint._track_costs(thunk, with_endpoints=endpoints)\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py\", line 553, in _track_costs\n",
            "    result: T = thunk()\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py\", line 733, in <lambda>\n",
            "    lambda: func(*bindings.args, **bindings.kwargs)\n",
            "  File \"/var/folders/w4/p920nxd539l9mzghrkxf765w0000gn/T/ipykernel_49892/1209908114.py\", line 15, in complete\n",
            "    completion = gemini_pro.complete(\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py\", line 159, in complete\n",
            "    images = [PIL.Image.open(doc.resolve_image()) for doc in image_documents]\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py\", line 159, in <listcomp>\n",
            "    images = [PIL.Image.open(doc.resolve_image()) for doc in image_documents]\n",
            "  File \"/opt/homebrew/lib/python3.9/site-packages/PIL/Image.py\", line 3305, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x1692c2c20>\n",
            "\n",
            "Unsure what the main input string is for the call to complete with args ['Identify the city where this photo was taken.', [ImageDocument(id_='fc15f81c-6580-4dec-903f-77815e8e341b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path=None, image_url='https://storage.googleapis.com/generativeai-downloads/data/scene.jpghttps://t3.ftcdn.net/jpg/01/76/97/96/240_F_176979696_hqfioFYq7pX13dmiu9ENrpsHZy1yM3Dt.jpg', text_embedding=None)]].\n",
            "Unsure what the main output string is for the call to complete.\n"
          ]
        },
        {
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x1692c2c20>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tru_gemini \u001b[38;5;28;01mas\u001b[39;00m recording:\n\u001b[0;32m----> 2\u001b[0m     gemini\u001b[38;5;241m.\u001b[39mcomplete(\n\u001b[1;32m      3\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentify the city where this photo was taken.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     image_documents\u001b[38;5;241m=\u001b[39mimage_documents\n\u001b[1;32m      5\u001b[0m     )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print(f\"{dir(tru_gemini)}\")\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/app.py:714\u001b[0m, in \u001b[0;36mApp.__exit__\u001b[0;34m(self, exc_type, exc_value, exc_tb)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecording_contexts\u001b[38;5;241m.\u001b[39mreset(ctx\u001b[38;5;241m.\u001b[39mtoken)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tru_gemini \u001b[38;5;28;01mas\u001b[39;00m recording:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mgemini\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIdentify the city where this photo was taken.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_documents\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print(f\"{dir(tru_gemini)}\")\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py:781\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;66;03m# If stack has only 1 thing on it, we are looking at a \"root\u001b[39;00m\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;66;03m# call\". Create a record of the result and notify the app:\u001b[39;00m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stack) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    779\u001b[0m         \u001b[38;5;66;03m# If this is a root call, notify app to add the completed record\u001b[39;00m\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;66;03m# into its containers:\u001b[39;00m\n\u001b[0;32m--> 781\u001b[0m         \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_add_record\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m            \u001b[49m\u001b[43msig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mret\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mperf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPerf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcost\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/app.py:762\u001b[0m, in \u001b[0;36mApp._on_add_record\u001b[0;34m(self, ctx, func, sig, bindings, ret, error, perf, cost)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;66;03m# May block on DB.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_error(record\u001b[38;5;241m=\u001b[39mrecord, error\u001b[38;5;241m=\u001b[39merror)\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    764\u001b[0m \u001b[38;5;66;03m# Will block on DB, but not on feedback evaluation, depending on\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# FeedbackMode:\u001b[39;00m\n\u001b[1;32m    766\u001b[0m record\u001b[38;5;241m.\u001b[39mfeedback_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_record(record\u001b[38;5;241m=\u001b[39mrecord)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py:732\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 732\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs_tally\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    737\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py:447\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs_tally\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm, with_bedrock)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack_all_costs_tally\u001b[39m(\n\u001b[1;32m    435\u001b[0m     thunk: Thunk[T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[T, Cost]:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# TODO: dedup async/sync\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    Track costs of all of the apis we can currently track, over the\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    execution of thunk.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     result, cbs \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_openai\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_openai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_hugs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_hugs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_litellm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_litellm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_bedrock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_bedrock\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cbs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;66;03m# Otherwise sum returns \"0\" below.\u001b[39;00m\n\u001b[1;32m    457\u001b[0m         costs \u001b[38;5;241m=\u001b[39m Cost()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py:396\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs\u001b[0;34m(thunk, with_openai, with_hugs, with_litellm, with_bedrock)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    390\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    391\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not initiallize endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPossibly missing key(s). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrulens_eval will not track costs/usage of this endpoint. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    394\u001b[0m             )\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_costs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_endpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py:553\u001b[0m, in \u001b[0;36mEndpoint._track_costs\u001b[0;34m(thunk, with_endpoints)\u001b[0m\n\u001b[1;32m    550\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(callback)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# Call the thunk.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m result: T \u001b[38;5;241m=\u001b[39m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# Return result and only the callbacks created here. Outer thunks might\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# return others.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, callbacks\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/trulens_eval/instruments.py:733\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    732\u001b[0m     rets, cost \u001b[38;5;241m=\u001b[39m Endpoint\u001b[38;5;241m.\u001b[39mtrack_all_costs_tally(\n\u001b[0;32m--> 733\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m     )\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    737\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
            "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mGemini.complete\u001b[0;34m(self, prompt, image_documents)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@instrument\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt, image_documents):\n\u001b[0;32m---> 15\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mgemini_pro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py:159\u001b[0m, in \u001b[0;36mGeminiMultiModal.complete\u001b[0;34m(self, prompt, image_documents, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, image_documents: Sequence[ImageDocument], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[0;32m--> 159\u001b[0m     images \u001b[38;5;241m=\u001b[39m [PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(doc\u001b[38;5;241m.\u001b[39mresolve_image()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m image_documents]\n\u001b[1;32m    160\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt, \u001b[38;5;241m*\u001b[39mimages], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_from_gemini_response(result)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/llama_index/multi_modal_llms/gemini.py:159\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, image_documents: Sequence[ImageDocument], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[0;32m--> 159\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m image_documents]\n\u001b[1;32m    160\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt, \u001b[38;5;241m*\u001b[39mimages], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion_from_gemini_response(result)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/PIL/Image.py:3305\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3303\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3304\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3305\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x1692c2c20>"
          ]
        }
      ],
      "source": [
        "with tru_gemini as recording:\n",
        "    gemini.complete(\n",
        "    prompt=\"Identify the city where this photo was taken.\",\n",
        "    image_documents=image_documents\n",
        "    )\n",
        "\n",
        "#print(f\"{dir(tru_gemini)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyR5IYXyRfaa"
      },
      "source": [
        "## Build Multi-Modal RAG for Restaurant Recommendation\n",
        "\n",
        "Our stack consists of TruLens + Gemini + LlamaIndex + Pydantic structured output capabilities.\n",
        "\n",
        "Pydantic structured output is great,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H33LK17nId5"
      },
      "source": [
        "### Download data to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCCX9AEenId5",
        "outputId": "53c0eee1-3864-47d2-a7c4-29835ae6aaa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "input_image_path = Path(\"google_restaurants\")\n",
        "if not input_image_path.exists():\n",
        "    Path.mkdir(input_image_path)\n",
        "\n",
        "!wget \"https://docs.google.com/uc?export=download&id=1Pg04p6ss0FlBgz00noHAOAJ1EYXiosKg\" -O ./google_restaurants/miami.png\n",
        "!wget \"https://docs.google.com/uc?export=download&id=1dYZy17bD6pSsEyACXx9fRMNx93ok-kTJ\" -O ./google_restaurants/orlando.png\n",
        "!wget \"https://docs.google.com/uc?export=download&id=1ShPnYVc1iL_TA1t7ErCFEAHT74-qvMrn\" -O ./google_restaurants/sf.png\n",
        "!wget \"https://docs.google.com/uc?export=download&id=1WjISWnatHjwL4z5VD_9o09ORWhRJuYqm\" -O ./google_restaurants/toronto.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJVO9lNDnId5"
      },
      "source": [
        "### Define Pydantic Class for Strucutred Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cNol-nemnId5"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './google_restaurants/miami.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m     nearby_tourist_places: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m     21\u001b[0m google_image_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./google_restaurants/miami.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoogle_image_url\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/PIL/Image.py:3243\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3240\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3243\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3244\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './google_restaurants/miami.png'"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class GoogleRestaurant(BaseModel):\n",
        "    \"\"\"Data model for a Google Restaurant.\"\"\"\n",
        "\n",
        "    restaurant: str\n",
        "    food: str\n",
        "    location: str\n",
        "    category: str\n",
        "    hours: str\n",
        "    price: str\n",
        "    rating: float\n",
        "    review: str\n",
        "    description: str\n",
        "    nearby_tourist_places: str\n",
        "\n",
        "\n",
        "google_image_url = \"./google_restaurants/miami.png\"\n",
        "image = Image.open(google_image_url).convert(\"RGB\")\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT0wZY2knId5"
      },
      "outputs": [],
      "source": [
        "from llama_index.multi_modal_llms import GeminiMultiModal\n",
        "from llama_index.program import MultiModalLLMCompletionProgram\n",
        "from llama_index.output_parsers import PydanticOutputParser\n",
        "\n",
        "prompt_template_str = \"\"\"\\\n",
        "    can you summarize what is in the image\\\n",
        "    and return the answer with json format \\\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def pydantic_gemini(\n",
        "    model_name, output_class, image_documents, prompt_template_str\n",
        "):\n",
        "    gemini_llm = GeminiMultiModal(\n",
        "        api_key=os.environ[\"GOOGLE_API_KEY\"], model_name=model_name\n",
        "    )\n",
        "\n",
        "    llm_program = MultiModalLLMCompletionProgram.from_defaults(\n",
        "        output_parser=PydanticOutputParser(output_class),\n",
        "        image_documents=image_documents,\n",
        "        prompt_template_str=prompt_template_str,\n",
        "        multi_modal_llm=gemini_llm,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    response = llm_program()\n",
        "    return response\n",
        "\n",
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "google_image_documents = SimpleDirectoryReader(\n",
        "    \"./google_restaurants\"\n",
        ").load_data()\n",
        "\n",
        "results = []\n",
        "for img_doc in google_image_documents:\n",
        "    pydantic_response = pydantic_gemini(\n",
        "        \"models/gemini-pro-vision\",\n",
        "        GoogleRestaurant,\n",
        "        [img_doc],\n",
        "        prompt_template_str,\n",
        "    )\n",
        "    # only output the results for miami for example along with image\n",
        "    if \"miami\" in img_doc.image_path:\n",
        "        for r in pydantic_response:\n",
        "            print(r)\n",
        "    results.append(pydantic_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZWjzsSkRfaa"
      },
      "source": [
        "### Construct Text Nodes for Building Vector Store. Store metadata and description for each restaurant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBcrWwGYRfaa"
      },
      "outputs": [],
      "source": [
        "from llama_index.schema import TextNode\n",
        "\n",
        "nodes = []\n",
        "for res in results:\n",
        "    text_node = TextNode()\n",
        "    metadata = {}\n",
        "    for r in res:\n",
        "        # set description as text of TextNode\n",
        "        if r[0] == \"description\":\n",
        "            text_node.text = r[1]\n",
        "        else:\n",
        "            metadata[r[0]] = r[1]\n",
        "    text_node.metadata = metadata\n",
        "    nodes.append(text_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrDnWgtbRfah"
      },
      "source": [
        "### Using Gemini Embedding for building Vector Store for Dense retrieval. Index Restaurants as nodes into Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ueV_FenRfah"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex, StorageContext, ServiceContext\n",
        "from llama_index.embeddings import GeminiEmbedding\n",
        "from llama_index.llms import Gemini\n",
        "from llama_index.vector_stores import QdrantVectorStore\n",
        "from llama_index import StorageContext\n",
        "import qdrant_client\n",
        "\n",
        "# Create a local Qdrant vector store\n",
        "client = qdrant_client.QdrantClient(path=\"qdrant_gemini_4\")\n",
        "\n",
        "vector_store = QdrantVectorStore(client=client, collection_name=\"collection\")\n",
        "\n",
        "# Using the embedding model to Gemini\n",
        "embed_model = GeminiEmbedding(\n",
        "    model_name=\"models/embedding-001\", api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
        ")\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=Gemini(), embed_model=embed_model\n",
        ")\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex(\n",
        "    nodes=nodes,\n",
        "    service_context=service_context,\n",
        "    storage_context=storage_context,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geZEOLcaRfah"
      },
      "source": [
        "### Using Gemini to synthesize the results and recommend the restaurants to user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmYNzEOCRfah"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=1,\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"recommend an inexpensive Orlando restaurant for me and its nearby tourist places\"\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYsRAvBlnId7"
      },
      "source": [
        "## Instrument and Evaluate `query_engine` with TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W71pyCPTnId8"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms import Gemini\n",
        "\n",
        "from trulens_eval import Provider\n",
        "from trulens_eval import Feedback\n",
        "from trulens_eval import Select\n",
        "\n",
        "from trulens_eval import LiteLLM\n",
        "from google.cloud import aiplatform\n",
        "aiplatform.init(\n",
        "    project = \"trulens-testing\",\n",
        "    location=\"us-central1\"\n",
        ")\n",
        "\n",
        "gemini_provider = LiteLLM(model_engine=\"gemini-pro\")\n",
        "\n",
        "from trulens_eval.feedback import Groundedness\n",
        "import numpy as np\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=gemini_provider)\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
        "    .on(Select.RecordCalls._response_synthesizer.get_response.args.text_chunks[0].collect())\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = (\n",
        "    Feedback(gemini_provider.relevance, name = \"Answer Relevance\")\n",
        "    .on_input()\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(gemini_provider.qs_relevance, name = \"Context Relevance\")\n",
        "    .on_input()\n",
        "    .on(Select.RecordCalls._response_synthesizer.get_response.args.text_chunks[0])\n",
        "    .aggregate(np.mean)\n",
        ")\n",
        "\n",
        "import re\n",
        "gemini_text = Gemini()\n",
        "\n",
        "# create a custom gemini feedback provider to rate affordability. Do it with len() and math and also with an LLM.\n",
        "class Gemini_Provider(Provider):\n",
        "    def affordable_math(self, text: str) -> float:\n",
        "        \"\"\"\n",
        "        Count the number of money signs using len(). Then subtract 1 and divide by 3.\n",
        "        \"\"\"\n",
        "        affordability = 1 - (\n",
        "            (len(text) - 1)/3)\n",
        "        return affordability\n",
        "\n",
        "    def affordable_llm(self, text: str) -> float:\n",
        "        \"\"\"\n",
        "        Count the number of money signs using an LLM. Then subtract 1 and take the reciprocal.\n",
        "        \"\"\"\n",
        "        prompt = f\"Count the number of characters in the text: {text}. Then subtract 1 and divide the result by 3. Last subtract from 1. Final answer:\"\n",
        "        gemini_response = gemini_text.complete(prompt).text\n",
        "        # gemini is a bit verbose, so do some regex to get the answer out.\n",
        "        float_pattern = r'[-+]?\\d*\\.\\d+|\\d+'\n",
        "        float_numbers = re.findall(float_pattern, gemini_response)\n",
        "        rightmost_float = float(float_numbers[-1])\n",
        "        affordability = rightmost_float\n",
        "        return affordability\n",
        "\n",
        "gemini_provider_custom = Gemini_Provider()\n",
        "f_affordable_math = Feedback(gemini_provider_custom.affordable_math, name = \"Affordability - Math\").on(Select.RecordCalls.retriever._index.storage_context.vector_stores.default.query.rets.nodes[0].metadata.price)\n",
        "f_affordable_llm = Feedback(gemini_provider_custom.affordable_llm, name = \"Affordability - LLM\").on(Select.RecordCalls.retriever._index.storage_context.vector_stores.default.query.rets.nodes[0].metadata.price)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEDKkdv_nId8"
      },
      "source": [
        "### Test the feedback function(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyDqriGanId8"
      },
      "outputs": [],
      "source": [
        "grounded.groundedness_measure_with_cot_reasons([\"\"\"('restaurant', 'La Mar by Gaston Acurio')\n",
        "('food', 'South American')\n",
        "('location', '500 Brickell Key Dr, Miami, FL 33131')\n",
        "('category', 'Restaurant')\n",
        "('hours', 'Open ⋅ Closes 11 PM')\n",
        "('price', 'Moderate')\n",
        "('rating', 4.4)\n",
        "('review', '4.4 (2,104)')\n",
        "('description', 'Chic waterfront find offering Peruvian & fusion fare, plus bars for cocktails, ceviche & anticucho.')\n",
        "('nearby_tourist_places', 'Brickell Key Park')\"\"\"], \"La Mar by Gaston Acurio is a delicious peruvian restaurant by the water\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs0UJwNynId8"
      },
      "outputs": [],
      "source": [
        "gemini_provider.qs_relevance(\"I'm hungry for Peruvian, and would love to eat by the water. Can you recommend a dinner spot?\",\n",
        "\"\"\"('restaurant', 'La Mar by Gaston Acurio')\n",
        "('food', 'South American')\n",
        "('location', '500 Brickell Key Dr, Miami, FL 33131')\n",
        "('category', 'Restaurant')\n",
        "('hours', 'Open ⋅ Closes 11 PM')\n",
        "('price', 'Moderate')\n",
        "('rating', 4.4)\n",
        "('review', '4.4 (2,104)')\n",
        "('description', 'Chic waterfront find offering Peruvian & fusion fare, plus bars for cocktails, ceviche & anticucho.')\n",
        "('nearby_tourist_places', 'Brickell Key Park')\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2byozgOmnId9"
      },
      "outputs": [],
      "source": [
        "gemini_provider.relevance(\"I'm hungry for Peruvian, and would love to eat by the water. Can you recommend a dinner spot?\",\n",
        "\"La Mar by Gaston Acurio is a delicious peruvian restaurant by the water\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFnYcV-QnId9"
      },
      "outputs": [],
      "source": [
        "gemini_provider_custom.affordable_math(\"$$\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfN42riRnId9"
      },
      "outputs": [],
      "source": [
        "gemini_provider_custom.affordable_llm(\"$$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVhHfOXinId9"
      },
      "source": [
        "### Set up instrumentation and eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD8Brkn4nId9"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruLlama\n",
        "\n",
        "tru_query_engine_recorder = TruLlama(query_engine,\n",
        "    app_id='LlamaIndex_App1',\n",
        "    feedbacks = [f_affordable_math, f_affordable_llm, f_context_relevance, f_groundedness, f_qa_relevance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4MUPZoynId-"
      },
      "outputs": [],
      "source": [
        "tru.stop_dashboard(force=True)\n",
        "tru.run_dashboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU1E0gVOnId-"
      },
      "source": [
        "### Run the app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm8S86PVnId_"
      },
      "outputs": [],
      "source": [
        "with tru_query_engine_recorder as recording:\n",
        "    query_engine.query(\"recommend an american restaurant in Orlando for me and its nearby tourist places\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4Y4p9nwnId_"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import Tru\n",
        "\n",
        "tru = Tru()\n",
        "tru.run_dashboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOClS6zXnId_"
      },
      "outputs": [],
      "source": [
        "tru.get_leaderboard(app_ids=['LlamaIndex_App1'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
